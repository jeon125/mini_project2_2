{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Step2 ì œê³µíŒŒì¼_AIë©´ì ‘ê´€ Agent_with Gradio**"],"metadata":{"id":"mSB2IiVH8B1v"}},{"cell_type":"markdown","metadata":{"id":"zU-xxYwejwGR"},"source":["## **1. í™˜ê²½ì¤€ë¹„**"]},{"cell_type":"markdown","metadata":{"id":"CdcBWhy_F_Hm"},"source":["### (1) êµ¬ê¸€ ë“œë¼ì´ë¸Œ"]},{"cell_type":"markdown","source":["#### 1) êµ¬ê¸€ ë“œë¼ì´ë¸Œ í´ë” ìƒì„±\n","* ìƒˆ í´ë”(project_genai)ë¥¼ ìƒì„±í•˜ê³ \n","* ì œê³µ ë°›ì€ íŒŒì¼ì„ ì—…ë¡œë“œ"],"metadata":{"id":"xUOpvAJGGJnL"}},{"cell_type":"markdown","source":["#### 2) êµ¬ê¸€ ë“œë¼ì´ë¸Œ ì—°ê²°"],"metadata":{"id":"4jUC5td4GLEF"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"tEfLUT6ZGEJi","colab":{"base_uri":"https://localhost:8080/"},"outputId":"839d5396-570f-485b-b334-a9a8420555c1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["### (2) ë¼ì´ë¸ŒëŸ¬ë¦¬"],"metadata":{"id":"PepxmQuiGzkX"}},{"cell_type":"code","source":["!pip install langchain_openai langchain_core langchain-community -q\n","!pip install -U langgraph\n","!pip install PyMuPDF python-docx gradio -q"],"metadata":{"id":"TwO3_Qx4PlM-","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d976d3ee-f3ef-431f-9b49-5328ad198e90"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: langgraph in /usr/local/lib/python3.12/dist-packages (1.0.2)\n","Requirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.12/dist-packages (from langgraph) (1.0.2)\n","Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.0.0)\n","Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langgraph) (1.0.2)\n","Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from langgraph) (0.2.9)\n","Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langgraph) (2.11.10)\n","Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.6.0)\n","Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (1.33)\n","Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (0.4.38)\n","Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (25.0)\n","Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (6.0.3)\n","Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (8.5.0)\n","Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (4.15.0)\n","Requirement already satisfied: ormsgpack>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph) (1.11.0)\n","Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.28.1)\n","Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11.4)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (0.4.2)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (4.11.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (2025.10.5)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.0.9)\n","Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.16.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core>=0.1->langgraph) (3.0.0)\n","Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n","Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (2.32.5)\n","Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (0.25.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (3.4.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (2.5.0)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.3.1)\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/base_command.py\", line 179, in exc_logging_wrapper\n","    status = run_func(*args)\n","             ^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/req_command.py\", line 67, in wrapper\n","    return func(self, options, args)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/commands/install.py\", line 447, in run\n","    conflicts = self._determine_conflicts(to_install)\n","                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/commands/install.py\", line 578, in _determine_conflicts\n","    return check_install_conflicts(to_install)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/operations/check.py\", line 101, in check_install_conflicts\n","    package_set, _ = create_package_set_from_installed()\n","                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/operations/check.py\", line 42, in create_package_set_from_installed\n","    dependencies = list(dist.iter_dependencies())\n","                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/metadata/importlib/_dists.py\", line 225, in iter_dependencies\n","    elif not extras and req.marker.evaluate({\"extra\": \"\"}):\n","                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/packaging/markers.py\", line 325, in evaluate\n","    return _evaluate_markers(self._markers, current_environment)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/packaging/markers.py\", line 225, in _evaluate_markers\n","    groups[-1].append(_eval_op(lhs_value, op, rhs_value))\n","                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/packaging/markers.py\", line 185, in _eval_op\n","    oper: Operator | None = _operators.get(op.serialize())\n","                                           ^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/packaging/_parser.py\", line 40, in serialize\n","    def serialize(self) -> str:\n","\n","KeyboardInterrupt\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/bin/pip3\", line 10, in <module>\n","    sys.exit(main())\n","             ^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/main.py\", line 80, in main\n","    return command.main(cmd_args)\n","           ^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/base_command.py\", line 100, in main\n","    return self._main(args)\n","           ^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/base_command.py\", line 232, in _main\n","    return run(options, args)\n","           ^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/base_command.py\", line 215, in exc_logging_wrapper\n","    logger.critical(\"Operation cancelled by user\")\n","  File \"/usr/lib/python3.12/logging/__init__.py\", line 1586, in critical\n","    self._log(CRITICAL, msg, args, **kwargs)\n","  File \"/usr/lib/python3.12/logging/__init__.py\", line 1684, in _log\n","    self.handle(record)\n","  File \"/usr/lib/python3.12/logging/__init__.py\", line 1700, in handle\n","    self.callHandlers(record)\n","  File \"/usr/lib/python3.12/logging/__init__.py\", line 1762, in callHandlers\n","    hdlr.handle(record)\n","  File \"/usr/lib/python3.12/logging/__init__.py\", line 1028, in handle\n","    self.emit(record)\n","  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/utils/logging.py\", line 177, in emit\n","    self.console.print(renderable, overflow=\"ignore\", crop=False, style=style)\n","  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/rich/console.py\", line 1685, in print\n","    render_options = self.options.update(\n","                     ^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/rich/console.py\", line 984, in options\n","    size=self.size,\n","         ^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/rich/console.py\", line 1003, in size\n","    if self.is_dumb_terminal:\n","       ^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/rich/console.py\", line 977, in is_dumb_terminal\n","    return self.is_terminal and is_dumb\n","           ^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/rich/console.py\", line 953, in is_terminal\n","    force_color = self._environ.get(\"FORCE_COLOR\")\n","                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"<frozen _collections_abc>\", line 807, in get\n","  File \"<frozen os>\", line 709, in __getitem__\n","KeyboardInterrupt\n","^C\n"]}]},{"cell_type":"code","source":["!pip install chromadb\n","!apt-get update\n","!apt-get install -y fonts-nanum\n","!pip install reportlab"],"metadata":{"id":"41RdMdLDkkwO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PS5BhycUFUMI"},"source":["### (3) OpenAI API Key í™•ì¸\n","* api_key.txt íŒŒì¼ì— ë‹¤ìŒì˜ í‚¤ë¥¼ ë“±ë¡í•˜ì„¸ìš”.\n","    * OPENAI_API_KEY"]},{"cell_type":"code","source":["import os\n","\n","def load_api_keys(filepath=\"api_key.txt\"):\n","    with open(filepath, \"r\") as f:\n","        for line in f:\n","            line = line.strip()\n","            if line and \"=\" in line:\n","                key, value = line.split(\"=\", 1)\n","                os.environ[key.strip()] = value.strip()\n","\n","path = '/content/drive/MyDrive/langchain/'\n","# API í‚¤ ë¡œë“œ ë° í™˜ê²½ë³€ìˆ˜ ì„¤ì •\n","load_api_keys(path + 'api_key.txt')"],"metadata":{"id":"AaZBGfeWNMRE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(os.environ['OPENAI_API_KEY'][:30])\n","path = '/content/drive/MyDrive/kt aivle/á„’á…¡á†«á„€á…§á†¼á„’á…®á†« á„ƒá…¢á„‹á…±á„’á…¢á†·/AI_á„†á…µá„‚á…µá„‘á…³á„…á…©á„Œá…¦á†¨á„á…³ 2á„á…¡_3á„‹á…µá†¯á„á…¡_á„‰á…µá†¯á„‰á…³á†¸á„Œá…¡á„…á…­/'"],"metadata":{"id":"GqSUhiv8wKxh","colab":{"base_uri":"https://localhost:8080/"},"outputId":"54cf5349-ecfd-4fa3-dbd7-bd3bf789cff4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["sk-proj-shXQh5RT2uL_Khb0wD_xrm\n"]}]},{"cell_type":"markdown","source":["## **2. App.py**\n","\n","* ì•„ë˜ ì½”ë“œì—, Step1 í˜¹ì€ ê³ ë„í™” ëœ Step2 íŒŒì¼ ì½”ë“œë¥¼ ë¶™ì¸ë‹¤.\n","    * ë¼ì´ë¸ŒëŸ¬ë¦¬\n","    * í•¨ìˆ˜ë“¤ê³¼ ê·¸ë˜í”„\n","* Gradio ì½”ë“œëŠ” ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ê±°ë‚˜ ì¼ë¶€ ìˆ˜ì • ê°€ëŠ¥"],"metadata":{"id":"ULAOaRHmShq1"}},{"cell_type":"code","source":["%%writefile app.py\n","\n","####### ì—¬ëŸ¬ë¶„ì˜ í•¨ìˆ˜ì™€ í´ë˜ìŠ¤ë¥¼ ëª¨ë“œ ì—¬ê¸°ì— ë¶™ì—¬ ë„£ìì‹œë‹¤. #######\n","## 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë”© ---------------------------------------------\n","import pandas as pd\n","import numpy as np\n","import os\n","import openai\n","import random\n","import ast\n","import fitz\n","from docx import Document\n","import json\n","import matplotlib.pyplot as plt\n","from math import pi\n","from langchain_core.messages import SystemMessage\n","\n","\n","from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Image\n","from reportlab.lib.pagesizes import A4\n","from reportlab.lib.styles import getSampleStyleSheet\n","from reportlab.pdfbase import pdfmetrics\n","from reportlab.pdfbase.cidfonts import UnicodeCIDFont\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n","\n","from typing import Annotated, Literal, Sequence, TypedDict, List, Dict\n","from langchain import hub\n","from langchain_core.messages import BaseMessage, HumanMessage\n","from langchain_core.output_parsers import StrOutputParser\n","from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n","from langchain_openai import ChatOpenAI\n","from langchain_community.embeddings import OpenAIEmbeddings\n","from langchain_community.vectorstores import Chroma\n","from langchain.output_parsers import CommaSeparatedListOutputParser\n","from langgraph.graph import StateGraph, END\n","\n","## ---------------- 1ë‹¨ê³„ : ì‚¬ì „ì¤€ë¹„ ----------------------\n","\n","# 1) íŒŒì¼ ì…ë ¥ --------------------\n","def extract_text_from_file(file_path: str) -> str:\n","    ext = os.path.splitext(file_path)[1].lower()\n","    if ext == \".pdf\":\n","        doc = fitz.open(file_path)\n","        text = \"\\n\".join(page.get_text() for page in doc)\n","        doc.close()\n","        return text\n","    elif ext == \".docx\":\n","        doc = Document(file_path)\n","        return \"\\n\".join(p.text for p in doc.paragraphs if p.text.strip())\n","    else:\n","        raise ValueError(\"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. PDF ë˜ëŠ” DOCXë§Œ í—ˆìš©ë©ë‹ˆë‹¤.\")\n","\n","# 2) State ì„ ì–¸ --------------------\n","class InterviewState(TypedDict):\n","    # ê³ ì • ì •ë³´\n","    resume_text: str\n","    resume_summary: str\n","    resume_keywords: List[str]\n","    question_strategy: Dict[str, Dict]\n","\n","    # ì¸í„°ë·° ë¡œê·¸\n","    current_question: str\n","    current_answer: str\n","    current_strategy: str\n","    conversation: List[Dict[str, str]]\n","    evaluation : List[Dict[str, str]]\n","    next_step : str\n","    reflection_status : str\n","    final_report : str\n","    pdf_path : str\n","\n","# 3) resume ë¶„ì„ --------------------\n","def analyze_resume(state: InterviewState) -> InterviewState:\n","    llm = ChatOpenAI(model_name='gpt-4.1-mini')\n","\n","    # ì´ë ¥ì„œ í•µì‹¬ ìš”ì•½\n","    summary_prompt = ChatPromptTemplate.from_messages([\n","        (\"system\", \"ë„ˆëŠ” ì´ë ¥ì„œ ë¶„ì„ ì „ë¬¸ê°€ì•¼.\"),\n","        (\"human\", \"ë©´ì ‘ ì§ˆë¬¸ì„ ìœ„í•´ {resume_text}ì˜ ë‚´ìš©ì„ ì •í™•í•˜ê²Œ íŒŒì•…í•˜ê³  ì‹¶ì–´. {resume_text}ì˜ í•µì‹¬ ë‚´ìš©ì„ 10ë¬¸ì¥ ì´ë‚´ë¡œ ìš”ì•½í•´ì¤˜.\")\n","    ])\n","\n","    summary_messages = summary_prompt.format_messages(resume_text = state['resume_text'])\n","    summary_response = llm.invoke(summary_messages)\n","    resume_summary = summary_response.content.strip()\n","\n","    # ì´ë ¥ì„œ ì£¼ìš” í‚¤ì›Œë“œ ì¶”ì¶œ\n","    keyword_prompt = ChatPromptTemplate.from_messages([\n","        (\"system\", \"ë„ˆëŠ” ì´ë ¥ì„œ ë¶„ì„ ì „ë¬¸ê°€ì•¼.\"),\n","        (\"human\", \"ë©´ì ‘ ì§ˆë¬¸ì˜ ë°©í–¥ì„±ì„ ì¡ì„ ìˆ˜ ìˆê²Œ {resume_text}ì—ì„œ ì£¼ìš” í‚¤ì›Œë“œ 10ê°œ ì´ë‚´ë¡œ ë½‘ì•„ì„œ ì‰¼í‘œë¡œ êµ¬ë¶„í•´ì„œ ë‚˜ì—´í•´ì¤˜.\")\n","    ])\n","    keyword_messages = keyword_prompt.format_messages(resume_text=state['resume_text'])\n","    keyword_response = llm.invoke(keyword_messages)\n","    resume_keywords = [kw.strip() for kw in keyword_response.content.split(',')]\n","\n","    return {\n","        **state,\n","        \"resume_summary\": resume_summary,\n","        \"resume_keywords\": resume_keywords,\n","    }\n","\n","# 4) ì§ˆë¬¸ ì „ëµ ìˆ˜ë¦½ --------------------\n","\n","def generate_question_strategy(state: InterviewState) -> InterviewState:\n","    llm = ChatOpenAI(model_name='gpt-4.1-mini')\n","\n","    # ì§ˆë¬¸ ì „ëµ ìˆ˜ë¦½\n","    s_msg = 'ë„ˆëŠ” 10ë…„ ì´ìƒ ê²½ë ¥ì˜ ë©´ì ‘ê´€ì´ì•¼.'\n","    h_msg = '''\n","    {resume_summary}ì™€ {resume_keywords}ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê°œì¸í™”ëœ ë©´ì ‘ ì§ˆë¬¸ì„ ë½‘ì„ ê±°ì•¼.\n","    ì•„ë˜ 3ê°€ì§€ ë¶„ì•¼ì— ëŒ€í•´ ê°ê° \"ì§ˆë¬¸ ë°©í–¥\"ê³¼ \"ì˜ˆì‹œ ì§ˆë¬¸\"ì„ í¬í•¨í•œ ì „ëµì„ JSON í˜•íƒœë¡œ ì‘ì„±í•´ì¤˜.\n","\n","    ë°˜ë“œì‹œ ì•„ë˜ í˜•ì‹ì„ ë”°ë¥´ì„¸ìš”:\n","    {{\n","        \"ê²½ë ¥ ë° ê²½í—˜\": {{\n","            \"ì§ˆë¬¸ ë°©í–¥\": \"ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±\",\n","            \"ì˜ˆì‹œ ì§ˆë¬¸\": [\"ì§ˆë¬¸1\", \"ì§ˆë¬¸2\"]\n","        }},\n","        \"ë™ê¸° ë° ì»¤ë®¤ë‹ˆì¼€ì´ì…˜\": {{\n","            \"ì§ˆë¬¸ ë°©í–¥\": \"ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±\",\n","            \"ì˜ˆì‹œ ì§ˆë¬¸\": [\"ì§ˆë¬¸1\", \"ì§ˆë¬¸2\"]\n","        }},\n","        \"ë…¼ë¦¬ì  ì‚¬ê³ \": {{\n","            \"ì§ˆë¬¸ ë°©í–¥\": \"ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±\",\n","            \"ì˜ˆì‹œ ì§ˆë¬¸\": [\"ì§ˆë¬¸1\", \"ì§ˆë¬¸2\"]\n","        }}\n","    }}\n","\n","    '''\n","\n","    strategy_prompt = ChatPromptTemplate.from_messages([\n","        (\"system\", s_msg),\n","        (\"human\", h_msg)\n","    ])\n","\n","    strategy_messages = strategy_prompt.format_messages(resume_summary = state['resume_summary'], resume_keywords = state['resume_keywords'])\n","    strategy_response = llm.invoke(strategy_messages)\n","    strategy_output = strategy_response.content.strip()\n","\n","    # JSON íŒŒì‹±\n","    try:\n","        strategy_dict = json.loads(strategy_output)\n","    except json.JSONDecodeError:\n","        print(\"âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨ - ë¬¸ìì—´ ê·¸ëŒ€ë¡œ ì €ì¥í•©ë‹ˆë‹¤.\")\n","        strategy_dict = {\"raw_output\": strategy_output}\n","\n","    return {\n","        **state,\n","        \"question_strategy\": strategy_dict\n","    }\n","\n","# 5) 1ë‹¨ê³„ í•˜ë‚˜ë¡œ ë¬¶ê¸° --------------------\n","\n","def preProcessing_Interview(file_path: str) -> InterviewState:\n","    # íŒŒì¼ ì…ë ¥\n","    resume_text = extract_text_from_file(file_path)\n","\n","    # state ì´ˆê¸°í™”\n","    initial_state: InterviewState = {\n","        \"resume_text\": resume_text,\n","        \"resume_summary\": '',\n","        \"resume_keywords\": [],\n","        \"question_strategy\": {},\n","\n","        \"current_question\": '',\n","        \"current_answer\": '',\n","        \"current_strategy\": '',\n","        \"conversation\": [],\n","        \"evaluation\": [],\n","        \"next_step\" : '',\n","        \"reflection_status\": '',\n","        \"final_report\" : '',\n","        \"pdf_path\" : ''\n","    }\n","\n","    # Resume ë¶„ì„\n","    state = analyze_resume(initial_state)\n","\n","    # ì§ˆë¬¸ ì „ëµ ìˆ˜ë¦½\n","    state = generate_question_strategy(state)\n","\n","    # ì²«ë²ˆì§¸ ì§ˆë¬¸ ìƒì„±\n","    selected_question = state['question_strategy']['ê²½ë ¥ ë° ê²½í—˜']['ì˜ˆì‹œ ì§ˆë¬¸'][0]\n","\n","    return {\n","            **state,\n","            \"current_question\": selected_question,\n","            \"current_strategy\": \"ê²½ë ¥ ë° ê²½í—˜\"\n","            }\n","\n","\n","## ---------------- 2ë‹¨ê³„ : ë©´ì ‘ Agent ----------------------\n","\n","# 1) ë‹µë³€ ì…ë ¥ --------------------\n","def update_current_answer(state: InterviewState, user_input) -> InterviewState:\n","    return {\n","        **state,\n","        \"current_answer\": user_input.strip()\n","    }\n","\n","# 2) ë‹µë³€ í‰ê°€ --------------------\n","def evaluate_answer(state: InterviewState) -> InterviewState:\n","    # ë‹µë³€ í‰ê°€\n","    llm = ChatOpenAI(model_name='gpt-4.1-mini')\n","\n","    s_msg = 'ë„ˆëŠ” 10ë…„ ì´ìƒ ê²½ë ¥ì˜ ë©´ì ‘ê´€ì´ì•¼.'\n","    h_msg = '''\n","    ì•„ë˜ ì§ˆë¬¸ê³¼ ë‹µë³€ì„ ë³´ê³  ë©´ì ‘ ë‹µë³€ì´ ì ì ˆí•œì§€ ì•„ë˜ 2ê°€ì§€ í•­ëª©ì„ ê°ê° ìƒ, ì¤‘, í•˜ë¡œ í‰ê°€í•´ì¤˜.\n","\n","    ì§ˆë¬¸: {current_question}\n","    ë‹µë³€: {current_answer}\n","\n","    í‰ê°€ í•­ëª©:\n","    1. ì§ˆë¬¸ê³¼ì˜ ê´€ë ¨ì„±\n","    - ìƒ: ì§ˆë¬¸ì˜ í•µì‹¬ ì˜ë„ì— ì •í™•íˆ ë¶€í•©í•˜ë©°, ì „ë°˜ì ì¸ ë‚´ìš©ì„ ëª…í™•íˆ ë‹¤ë£¸\n","    - ì¤‘: ì§ˆë¬¸ê³¼ ê´€ë ¨ì€ ìˆì§€ë§Œ í•µì‹¬ í¬ì¸íŠ¸ê°€ ë¶€ë¶„ì ìœ¼ë¡œ ëˆ„ë½ë¨\n","    - í•˜: ì§ˆë¬¸ê³¼ ê´€ë ¨ì´ ì•½í•˜ê±°ë‚˜ ì—‰ëš±í•œ ë‚´ìš© ì¤‘ì‹¬\n","\n","    2. ë‹µë³€ì˜ êµ¬ì²´ì„±\n","    - ìƒ: ì§ˆë¬¸ì˜ í•µì‹¬ì ì¸ ë‚´ìš©ì„ êµ¬ì²´ì ìœ¼ë¡œ ì„œìˆ í•¨\n","    - ì¤‘: ë‹µë³€ì— ë¶€ë¶„ì ìœ¼ë¡œ ë‘ë£¨ë­‰ìˆ í•œ ë‚´ìš©ì´ ì„ì—¬ìˆìŒ\n","    - í•˜: ë‹µë³€ì´ ë„ˆë¬´ ì§§ê±°ë‚˜ ë‹µë³€ìê°€ êµ¬ì²´ì ìœ¼ë¡œ ì–´ë–¤ í–‰ë™ì„ í–ˆê³  ì–´ë–¤ ìƒê°ì„ í–ˆëŠ”ì§€ ë“œëŸ¬ë‚˜ìˆì§€ ì•ŠìŒ\n","\n","    ì¶œë ¥ í˜•ì‹(JSON):\n","    {{\n","        \"ì§ˆë¬¸ê³¼ì˜ ê´€ë ¨ì„±\": \"ìƒ/ì¤‘/í•˜ ì¤‘ í•˜ë‚˜\",\n","        \"ë‹µë³€ì˜ êµ¬ì²´ì„±\": \"ìƒ/ì¤‘/í•˜ ì¤‘ í•˜ë‚˜\"\n","    }}\n","    '''\n","\n","    evaluate_prompt = ChatPromptTemplate.from_messages([\n","        (\"system\", s_msg),\n","        (\"human\", h_msg)\n","    ])\n","\n","    evaluate_messages = evaluate_prompt.format_messages(current_question = state[\"current_question\"], current_answer = state[\"current_answer\"])\n","    evaluate_response = llm.invoke(evaluate_messages)\n","    evaluate_output = evaluate_response.content.strip()\n","\n","    try:\n","        eval_dict = json.loads(evaluate_output)\n","    except json.JSONDecodeError:\n","        # í˜•ì‹ì´ ì•ˆ ë§ìœ¼ë©´ fallback ì²˜ë¦¬\n","        eval_dict = {\"ì§ˆë¬¸ê³¼ì˜ ê´€ë ¨ì„±\": \"ì¤‘\", \"ë‹µë³€ì˜ êµ¬ì²´ì„±\": \"ì¤‘\"}\n","\n","    conversation = state.get(\"conversation\", [])\n","    evaluation = state.get(\"evaluation\", [])\n","\n","    conversation.append({\n","        \"ì§ˆë¬¸\": state[\"current_question\"],\n","        \"ë‹µë³€\": state[\"current_answer\"]\n","    })\n","    evaluation.append(eval_dict)\n","\n","    return {\n","        **state,\n","        \"conversation\": conversation,\n","        \"evaluation\": evaluation\n","    }\n","\n","# ë°˜ì¶” ë…¸ë“œ: ìµœê·¼ í‰ê°€ê°€ ì ì ˆí•œì§€ ë˜ëŒì•„ë³´ê³  íŒë‹¨ (ë³´ì™„ í•„ìš” ì—¬ë¶€ í¬í•¨)\n","def reflect_node(state: InterviewState) -> InterviewState:\n","    llm = ChatOpenAI(model_name='gpt-4.1-mini')\n","\n","    s_msg = \"ë„ˆëŠ” 10ë…„ ì´ìƒ ê²½ë ¥ì˜ ë©´ì ‘ê´€ì´ì•¼.\"\n","    h_msg = '''\n","    {current_question} ì§ˆë¬¸ê³¼ {current_answer} ë‹µë³€ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ {evaluation} ì´ëŸ° í‰ê°€ë¥¼ ë‚´ë ¸ì—ˆëŠ”ë° ì´ í‰ê°€ê°€ ì ì ˆí•œì§€ ë‹¤ì‹œ íŒë‹¨í•´ì¤˜.\n","    í‰ê°€ ê¸°ì¤€ì€ ì•„ë˜ì™€ ê°™ì•˜ì–´. ì´ ê¸°ì¤€ì— ë”°ë¼ í‰ê°€ê°€ ì œëŒ€ë¡œ ëëŠ”ì§€ í™•ì¸í•´ì„œ ì œëŒ€ë¡œ íŒë‹¨ ëìœ¼ë©´ \"ì •ìƒ\"ì´ë¼ê³  í•˜ê³  ë‹¤ì‹œ í‰ê°€í•´ì•¼ í•œë‹¤ê³  íŒë‹¨ë˜ë©´ \"ì¬í‰ê°€ í•„ìš”\"ë¼ê³  ë§í•´ì¤˜.\n","    ë°˜ë“œì‹œ \"ì •ìƒ\" ë˜ëŠ” \"ì¬í‰ê°€ í•„ìš”\" ì¤‘ í•˜ë‚˜ë§Œ ì¶œë ¥í•˜ë„ë¡ í•´.\n","\n","    í‰ê°€ ê¸°ì¤€:\n","    ì•„ë˜ ì§ˆë¬¸ê³¼ ë‹µë³€ì„ ë³´ê³  ë©´ì ‘ ë‹µë³€ì´ ì ì ˆí•œì§€ ì•„ë˜ 2ê°€ì§€ í•­ëª©ì„ ê°ê° ìƒ, ì¤‘, í•˜ë¡œ í‰ê°€í•´ì¤˜.\n","\n","    ì§ˆë¬¸: {current_question}\n","    ë‹µë³€: {current_answer}\n","\n","    í‰ê°€ í•­ëª©:\n","    1. ì§ˆë¬¸ê³¼ì˜ ê´€ë ¨ì„±\n","    - ìƒ: ì§ˆë¬¸ì˜ í•µì‹¬ ì˜ë„ì— ì •í™•íˆ ë¶€í•©í•˜ë©°, ì „ë°˜ì ì¸ ë‚´ìš©ì„ ëª…í™•íˆ ë‹¤ë£¸\n","    - ì¤‘: ì§ˆë¬¸ê³¼ ê´€ë ¨ì€ ìˆì§€ë§Œ í•µì‹¬ í¬ì¸íŠ¸ê°€ ë¶€ë¶„ì ìœ¼ë¡œ ëˆ„ë½ë¨\n","    - í•˜: ì§ˆë¬¸ê³¼ ê´€ë ¨ì´ ì•½í•˜ê±°ë‚˜ ì—‰ëš±í•œ ë‚´ìš© ì¤‘ì‹¬\n","\n","    2. ë‹µë³€ì˜ êµ¬ì²´ì„±\n","    - ìƒ: ì§ˆë¬¸ì˜ í•µì‹¬ì ì¸ ë‚´ìš©ì„ êµ¬ì²´ì ìœ¼ë¡œ ì„œìˆ í•¨\n","    - ì¤‘: ë‹µë³€ì— ë¶€ë¶„ì ìœ¼ë¡œ ë‘ë£¨ë­‰ìˆ í•œ ë‚´ìš©ì´ ì„ì—¬ìˆìŒ\n","    - í•˜: ë‹µë³€ì´ ë„ˆë¬´ ì§§ê±°ë‚˜ ë‹µë³€ìê°€ êµ¬ì²´ì ìœ¼ë¡œ ì–´ë–¤ í–‰ë™ì„ í–ˆê³  ì–´ë–¤ ìƒê°ì„ í–ˆëŠ”ì§€ ë“œëŸ¬ë‚˜ìˆì§€ ì•ŠìŒ\n","    '''\n","\n","    # ì´ë ¥ì„œ í•µì‹¬ ìš”ì•½\n","    reflect_prompt = ChatPromptTemplate.from_messages([\n","        (\"system\", s_msg),\n","        (\"human\", h_msg)\n","    ])\n","\n","    reflect_messages = reflect_prompt.format_messages(current_question = state['current_question'], current_answer = state['current_answer'], evaluation = state['evaluation'][-1])\n","    reflect_response = llm.invoke(reflect_messages)\n","    reflect_summary = reflect_response.content.strip()\n","\n","    return {\n","        **state,\n","        \"reflection_status\": reflect_summary\n","    }\n","\n","def re_evaluate_answer(state: InterviewState) -> InterviewState:\n","    # ë‹µë³€ í‰ê°€\n","    llm = ChatOpenAI(model_name='gpt-4.1-mini')\n","\n","    s_msg = 'ë„ˆëŠ” 10ë…„ ì´ìƒ ê²½ë ¥ì˜ ë©´ì ‘ê´€ì´ì•¼.'\n","    h_msg = '''\n","    ì•„ë˜ ì§ˆë¬¸ê³¼ ë‹µë³€ì„ ë³´ê³  ë©´ì ‘ ë‹µë³€ì´ ì ì ˆí•œì§€ ì•„ë˜ 2ê°€ì§€ í•­ëª©ì„ ê°ê° ìƒ, ì¤‘, í•˜ë¡œ ë‹¤ì‹œ í‰ê°€í•´ì¤˜. í‰ê°€ í•­ëª©ê³¼ ê¸°ì¤€ì— ë§ê²Œ ì •í™•í•˜ê²Œ ì œëŒ€ë¡œ í‰ê°€í•´ì¤˜.\n","\n","    ì§ˆë¬¸: {current_question}\n","    ë‹µë³€: {current_answer}\n","\n","    í‰ê°€ í•­ëª©:\n","    1. ì§ˆë¬¸ê³¼ì˜ ê´€ë ¨ì„±\n","    - ìƒ: ì§ˆë¬¸ì˜ í•µì‹¬ ì˜ë„ì— ì •í™•íˆ ë¶€í•©í•˜ë©°, ì „ë°˜ì ì¸ ë‚´ìš©ì„ ëª…í™•íˆ ë‹¤ë£¸\n","    - ì¤‘: ì§ˆë¬¸ê³¼ ê´€ë ¨ì€ ìˆì§€ë§Œ í•µì‹¬ í¬ì¸íŠ¸ê°€ ë¶€ë¶„ì ìœ¼ë¡œ ëˆ„ë½ë¨\n","    - í•˜: ì§ˆë¬¸ê³¼ ê´€ë ¨ì´ ì•½í•˜ê±°ë‚˜ ì—‰ëš±í•œ ë‚´ìš© ì¤‘ì‹¬\n","\n","    2. ë‹µë³€ì˜ êµ¬ì²´ì„±\n","    - ìƒ: ì§ˆë¬¸ì˜ í•µì‹¬ì ì¸ ë‚´ìš©ì„ êµ¬ì²´ì ìœ¼ë¡œ ì„œìˆ í•¨\n","    - ì¤‘: ë‹µë³€ì— ë¶€ë¶„ì ìœ¼ë¡œ ë‘ë£¨ë­‰ìˆ í•œ ë‚´ìš©ì´ ì„ì—¬ìˆìŒ\n","    - í•˜: ë‹µë³€ì´ ë„ˆë¬´ ì§§ê±°ë‚˜ ë‹µë³€ìê°€ êµ¬ì²´ì ìœ¼ë¡œ ì–´ë–¤ í–‰ë™ì„ í–ˆê³  ì–´ë–¤ ìƒê°ì„ í–ˆëŠ”ì§€ ë“œëŸ¬ë‚˜ìˆì§€ ì•ŠìŒ\n","\n","    ì¶œë ¥ í˜•ì‹(JSON):\n","    {{\n","        \"ì§ˆë¬¸ê³¼ì˜ ê´€ë ¨ì„±\": \"ìƒ/ì¤‘/í•˜ ì¤‘ í•˜ë‚˜\",\n","        \"ë‹µë³€ì˜ êµ¬ì²´ì„±\": \"ìƒ/ì¤‘/í•˜ ì¤‘ í•˜ë‚˜\"\n","    }}\n","    '''\n","\n","    evaluate_prompt = ChatPromptTemplate.from_messages([\n","        (\"system\", s_msg),\n","        (\"human\", h_msg)\n","    ])\n","\n","    evaluate_messages = evaluate_prompt.format_messages(current_question = state[\"current_question\"], current_answer = state[\"current_answer\"])\n","    evaluate_response = llm.invoke(evaluate_messages)\n","    evaluate_output = evaluate_response.content.strip()\n","\n","    try:\n","        eval_dict = json.loads(evaluate_output)\n","    except json.JSONDecodeError:\n","        # í˜•ì‹ì´ ì•ˆ ë§ìœ¼ë©´ fallback ì²˜ë¦¬\n","        eval_dict = {\"ì§ˆë¬¸ê³¼ì˜ ê´€ë ¨ì„±\": \"ì¤‘\", \"ë‹µë³€ì˜ êµ¬ì²´ì„±\": \"ì¤‘\"}\n","\n","    evaluation = state.get(\"evaluation\", [])\n","    if evaluation:\n","        evaluation[-1] = eval_dict  # ê¸°ì¡´ ë§ˆì§€ë§‰ í‰ê°€ ë®ì–´ì“°ê¸°\n","    else:\n","        evaluation.append(eval_dict)  # ë¦¬ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìœ¼ë©´ ìƒˆë¡œ ì¶”ê°€\n","\n","    return {\n","        **state,\n","        \"evaluation\": evaluation\n","    }\n","\n","# 3) ì¸í„°ë·° ì§„í–‰ ê²€í†  --------------------\n","def decide_next_step(state: InterviewState) -> InterviewState:\n","    conv = state.get('conversation', [])\n","    if len(conv) >= 5:\n","        return {**state, 'next_step': 'end'}\n","    evals = state.get('evaluation', [])\n","    recent = evals[-1] if evals else None\n","    if isinstance(recent, dict):\n","        grades = list(recent.values())\n","    elif isinstance(recent, (list, tuple, set)):\n","        grades = list(recent)\n","    elif recent is None:\n","        grades = []\n","    else:\n","        grades = [recent]\n","    strategies=['ê²½ë ¥ ë° ê²½í—˜','ë™ê¸° ë° ì»¤ë®¤ë‹ˆì¼€ì´ì…˜','ë…¼ë¦¬ì  ì‚¬ê³ ']\n","    selected_strategy=state['current_strategy']\n","    remain=[x for x in strategies if x not in selected_strategy]\n","    choice=random.choice(remain)\n","    if any(g == 'ìƒ' for g in grades):\n","        return {**state, 'next_step': '',\n","        'current_strategy':choice\n","        }\n","    if any(g == 'í•˜' for g in grades):\n","        return {**state, 'next_step': '',\n","        'current_strategy':choice\n","        }\n","    if grades and all(g == 'ì¤‘' for g in grades):\n","        return {**state, 'next_step': ''}\n","    return {**state, 'next_step': ''}\n","\n","# 4) ì§ˆë¬¸ ìƒì„± --------------------\n","def generate_question(state: InterviewState) -> InterviewState:\n","    # ì—¬ê¸°ì— ì½”ë“œë¥¼ ì™„ì„±í•©ë‹ˆë‹¤.\n","    llm = ChatOpenAI(model_name='gpt-4.1-mini')\n","    embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n","\n","    # --------------------------------í¬ë¡œë§ˆdb-------------------------------------#\n","    DB_DIRECTORY = \"/content/drive/MyDrive/kt aivle/á„’á…¡á†«á„€á…§á†¼á„’á…®á†« á„ƒá…¢á„‹á…±á„’á…¢á†·/chroma_db\"\n","\n","    if os.path.exists(DB_DIRECTORY): # chroma dbê°€ ì¡´ì¬í•  ê²½ìš°\n","      vectorstore = Chroma(\n","          persist_directory=DB_DIRECTORY,\n","          embedding_function=embedding_model\n","      )\n","\n","    else: # chroma dbê°€ ì—†ì„ ê²½ìš°, ì§ì ‘ ìƒì„±\n","      s_prompt_1 = ChatPromptTemplate.from_messages([\n","          (\"system\", \"\"\"ë„ˆëŠ” ì´ë ¥ì„œ ë¶„ì„ ì „ë¬¸ê°€ì•¼.\n","          ë°˜ë“œì‹œ ì•„ë˜ ìš”ì²­ëœ JSON í˜•ì‹ì„ ë”°ë¥´ì„¸ìš”:\n","\n","          {{\n","              \"ê²½ë ¥ ë° ê²½í—˜\": {{\n","                  \"ìœ ì‚¬ ì§ˆë¬¸1\": \"...\",\n","                  \"ìœ ì‚¬ ì§ˆë¬¸2\": \"...\",\n","                  \"ìœ ì‚¬ ì§ˆë¬¸3\": \"...\"\n","              }},\n","              \"ë™ê¸° ë° ì»¤ë®¤ë‹ˆì¼€ì´ì…˜\": {{\n","                  \"ìœ ì‚¬ ì§ˆë¬¸1\": \"...\",\n","                  \"ìœ ì‚¬ ì§ˆë¬¸2\": \"...\",\n","                  \"ìœ ì‚¬ ì§ˆë¬¸3\": \"...\"\n","              }},\n","              \"ë…¼ë¦¬ì  ì‚¬ê³ \": {{\n","                  \"ìœ ì‚¬ ì§ˆë¬¸1\": \"...\",\n","                  \"ìœ ì‚¬ ì§ˆë¬¸2\": \"...\",\n","                  \"ìœ ì‚¬ ì§ˆë¬¸3\": \"...\"\n","              }}\n","          }}\n","          \"\"\"),\n","          (\"human\", '''{state} ë‚´ìš© ì¤‘ ì´ë ¥ì„œ ìš”ì•½, í‚¤ì›Œë“œ, ì§ˆë¬¸ì „ëµ, ì´ì „ ì§ˆë¬¸ê³¼ ë‹µë³€, í‰ê°€ ë“±ì„ ê¸°ë°˜ìœ¼ë¡œ\n","          ì§€ì›ìì˜ ì‚¬ê³ ë ¥, ë¬¸ì œ í•´ê²° ë°©ì‹, í˜¹ì€ ê¸°ìˆ ì  ê¹Šì´ë¥¼ ë” í™•ì¸í•  ìˆ˜ ìˆë„ë¡ ì¶”ê°€ì ì¸ ì‹¬í™” ì¸í„°ë·° ì§ˆë¬¸ë“¤ì„ ìœ„í•œ ì˜ˆì‹œ ìœ ì‚¬ ì§ˆë¬¸ë“¤ì„ 3ê°€ì§€ ì£¼ì œì— 3ê°œì”© json í˜•íƒœë¡œ ë§Œë“¤ì–´ì¤˜. ì´ì „ ì§ˆë¬¸ê³¼ ì¤‘ë³µëœ ì§ˆë¬¸ì€ ì•ˆë¼.\n","          ''')\n","      ])\n","\n","      s_messages_1 = s_prompt_1.format_messages(state=state)\n","      response_1 = llm.invoke(s_messages_1)\n","      resume_evaluation = response_1.content.strip()\n","\n","      try:\n","          data = json.loads(resume_evaluation)\n","          question_list: List[str] = []\n","          for category, questions in data.items():\n","              for key, question in questions.items():\n","                  question_list.append(question)\n","      except json.JSONDecodeError:\n","              question_list = [resume_evaluation]\n","      vectorstore = Chroma.from_texts(question_list, embedding_model)#, persist_directory=\"./chroma_db\")\n","\n","    # --------------------------------dbë¡œë¶€í„° ê²€ìƒ‰-------------------------------------#\n","\n","    query = state.get(\"current_strategy\", \"\")\n","    keyword = state.get(\"resume_keywords\", [])\n","\n","    query += \", \".join(keyword)\n","\n","    retrieved_docs = vectorstore.similarity_search(query, k=3)\n","\n","    content = vectorstore.get(limit=100, include=[\"documents\"])\n","\n","    reference_questions = \"\\n\".join([f\"- {doc.page_content}\" for doc in retrieved_docs])\n","\n","    # --------------------------------ìµœì¢… ì§ˆë¬¸ ìƒì„±-------------------------------------#\n","\n","    s_prompt = ChatPromptTemplate.from_messages([\n","        (\"system\", \"ë„Œ ì´ë ¥ì„œ ë¶„ì„ ì „ë¬¸ê°€ì•¼.\"),\n","        (\"human\", '''{state} ë‚´ìš© ì¤‘ ì´ë ¥ì„œ ìš”ì•½, í‚¤ì›Œë“œ, ì§ˆë¬¸ì „ëµ, ì´ì „ ì§ˆë¬¸ê³¼ ë‹µë³€, í‰ê°€, ê·¸ë¦¬ê³  {similar_questions}ì˜ ìœ ì‚¬ ì§ˆë¬¸ ë“±ì„ ê¸°ë°˜ìœ¼ë¡œ\n","    ì§€ì›ìì˜ ì‚¬ê³ ë ¥, ë¬¸ì œ í•´ê²° ë°©ì‹, í˜¹ì€ ê¸°ìˆ ì  ê¹Šì´ë¥¼ ë” í™•ì¸í•  ìˆ˜ ìˆë„ë¡ ì¶”ê°€ì ì¸ ì‹¬í™” ì¸í„°ë·° ì§ˆë¬¸ì„ í•˜ë‚˜ ë§Œë“¤ì–´ì¤˜. ì§ˆë¬¸ ì™¸ì˜ ë‹¤ë¥¸ ì„¤ëª…ì´ë‚˜ ë¬¸ì¥ì€ í•„ìš” ì—†ì–´.\n","    ìœ ì‚¬ ì§ˆë¬¸ì€ ì°¸ê³ ë§Œ í•´ì•¼í•˜ê³ , ìœ ì‚¬ì§ˆë¬¸ê³¼ ê°™ì€ ì§ˆë¬¸ì´ ë‚˜ì˜¤ë©´ ì•ˆë¼.ì§ˆë¬¸ì€ {strategy} ê´€ë ¨í•œ ì§ˆë¬¸ì´ì—¬ì•¼í•´. ì´ì „ ì§ˆë¬¸ê³¼ ì¤‘ë³µëœ ì§ˆë¬¸ì€ ì•ˆë¼.\n","    ''')\n","    ])\n","    s_messages = s_prompt.format_messages(state=state, similar_questions=reference_questions, strategy=state[\"current_strategy\"])\n","    response = llm.invoke(s_messages)\n","\n","    # return ì½”ë“œëŠ” ì œê³µí•©ë‹ˆë‹¤.\n","\n","    return {\n","        **state,\n","        \"current_question\": response.content.strip(),\n","        \"current_answer\": \"\"\n","    }\n","\n","\n","# 5) ì¸í„°ë·° í”¼ë“œë°± ë³´ê³ ì„œ --------------------\n","def summarize_interview(state: InterviewState) -> InterviewState:\n","\n","    print('\\n' + '='*80)\n","    print('[ì¸í„°ë·° ì¢…ë£Œ ë¦¬í¬íŠ¸ - ìƒ/ì¤‘/í•˜ ê¸°ë³¸ í‰ê°€ + STAR ìƒì„¸ í‰ê°€]')\n","    print('='*80)\n","    # 1. ì§ˆë¬¸ë³„ ë‹µë³€ ë° í‰ê°€ ì¶œë ¥\n","    for i, conv in enumerate(state['conversation']):\n","        print(f\"\\n[ì§ˆë¬¸ {i+1}] {conv['ì§ˆë¬¸']}\")\n","        print(f\"[ë‹µë³€ {i+1}] {conv['ë‹µë³€']}\")\n","\n","        eval_data = state[\"evaluation\"][i]\n","\n","        # ê¸°ë³¸ í‰ê°€ (ìƒ/ì¤‘/í•˜)\n","        basic_eval = eval_data.get(\"ê¸°ë³¸í‰ê°€\", {})\n","        print(f\"\\nğŸ“Š [ê¸°ë³¸ í‰ê°€]\")\n","        print(f\"  - ì§ˆë¬¸ ê´€ë ¨ì„±: {basic_eval.get('ì§ˆë¬¸ê³¼ì˜_ê´€ë ¨ì„±', 'N/A')}\")\n","        print(f\"  - ë‹µë³€ êµ¬ì²´ì„±: {basic_eval.get('ë‹µë³€ì˜_êµ¬ì²´ì„±', 'N/A')}\")\n","        if 'ê¸°ë³¸í‰ê°€_ê·¼ê±°' in basic_eval:\n","            print(f\"  - ê·¼ê±°: {basic_eval['ê¸°ë³¸í‰ê°€_ê·¼ê±°']}\")\n","\n","        # STAR ìƒì„¸ í‰ê°€\n","        star_eval = eval_data.get(\"STARí‰ê°€\", {})\n","        print(f\"\\nâ­ [STAR ìƒì„¸ í‰ê°€]\")\n","        print(f\"  - S(ìƒí™©): {star_eval.get('S_ìƒí™©ì„¤ëª…', 'N/A')}ì \")\n","        print(f\"  - T(ì—­í• ): {star_eval.get('T_ì—­í• ëª©í‘œ', 'N/A')}ì \")\n","        print(f\"  - A(í–‰ë™): {star_eval.get('A_í–‰ë™ê²°ì •', 'N/A')}ì \")\n","        print(f\"  - R(ê²°ê³¼): {star_eval.get('R_ê²°ê³¼ì„±ê³¼', 'N/A')}ì \")\n","        print(f\"  - í˜‘ë™ì„±: {star_eval.get('í˜‘ë™ì„±', 'N/A')}ì \")\n","        if 'STARí‰ê°€_ê·¼ê±°' in star_eval:\n","            print(f\"  - ê·¼ê±°: {star_eval['STARí‰ê°€_ê·¼ê±°']}\")\n","\n","        print('-'*80)\n","\n","\n","    # 2. ì „ì²´ í‰ê·  - STAR ì ìˆ˜ ê³„ì‚°\n","    print('\\n' + '='*80)\n","    print('[STAR ì¢…í•© í‰ê°€ - ì „ì²´ í‰ê· ]')\n","    print('='*80)\n","\n","    categories = ['S_ìƒí™©ì„¤ëª…', 'T_ì—­í• ëª©í‘œ', 'A_í–‰ë™ê²°ì •', 'R_ê²°ê³¼ì„±ê³¼', 'í˜‘ë™ì„±']\n","    category_names = ['S (ìƒí™©)', 'T (ì—­í• )', 'A (í–‰ë™)', 'R (ê²°ê³¼)', 'í˜‘ë™ì„±']\n","\n","    avg_scores = {}\n","    for cat in categories:\n","        scores = [eval_data.get(\"STARí‰ê°€\", {}).get(cat, 3) for eval_data in state[\"evaluation\"]]\n","        avg_scores[cat] = round(sum(scores) / len(scores), 1)\n","\n","    for cat, display_name in zip(categories, category_names):\n","        print(f\"{display_name}: {avg_scores[cat]}ì \")\n","\n","    # 3. ìƒ/ì¤‘/í•˜ ë¹ˆë„ ë¶„ì„\n","    print('\\n' + '='*80)\n","    print('[ê¸°ë³¸ í‰ê°€ ìš”ì•½]')\n","    print('='*80)\n","\n","    relevance_counts = {\"ìƒ\": 0, \"ì¤‘\": 0, \"í•˜\": 0}\n","    specificity_counts = {\"ìƒ\": 0, \"ì¤‘\": 0, \"í•˜\": 0}\n","\n","    for eval_data in state[\"evaluation\"]:\n","        basic = eval_data.get(\"ê¸°ë³¸í‰ê°€\", {})\n","        rel = basic.get(\"ì§ˆë¬¸ê³¼ì˜_ê´€ë ¨ì„±\", \"ì¤‘\")\n","        spec = basic.get(\"ë‹µë³€ì˜_êµ¬ì²´ì„±\", \"ì¤‘\")\n","        relevance_counts[rel] = relevance_counts.get(rel, 0) + 1\n","        specificity_counts[spec] = specificity_counts.get(spec, 0) + 1\n","\n","    print(f\"ì§ˆë¬¸ ê´€ë ¨ì„±: ìƒ {relevance_counts['ìƒ']}ê°œ, ì¤‘ {relevance_counts['ì¤‘']}ê°œ, í•˜ {relevance_counts['í•˜']}ê°œ\")\n","    print(f\"ë‹µë³€ êµ¬ì²´ì„±: ìƒ {specificity_counts['ìƒ']}ê°œ, ì¤‘ {specificity_counts['ì¤‘']}ê°œ, í•˜ {specificity_counts['í•˜']}ê°œ\")\n","\n","    # 4. ë ˆì´ë” ì°¨íŠ¸ ìƒì„± (STAR ê¸°ì¤€)\n","    try:\n","        values = [avg_scores[cat] for cat in categories]\n","\n","        # ë ˆì´ë” ì°¨íŠ¸ ì„¤ì •\n","        N = len(categories)\n","        angles = [n / float(N) * 2 * pi for n in range(N)]\n","        values += values[:1]\n","        angles += angles[:1]\n","\n","        fig, ax = plt.subplots(figsize=(10, 8), subplot_kw=dict(projection='polar'))\n","\n","        # ì°¨íŠ¸ ê·¸ë¦¬ê¸°\n","        ax.plot(angles, values, 'o-', linewidth=2.5, color='#2E86DE', label='STAR í‰ê°€')\n","        ax.fill(angles, values, alpha=0.3, color='#2E86DE')\n","\n","        # ì¹´í…Œê³ ë¦¬ ë ˆì´ë¸”\n","        ax.set_xticks(angles[:-1])\n","        ax.set_xticklabels(category_names, size=12, weight='bold')\n","\n","        # Yì¶• ì„¤ì •\n","        ax.set_ylim(0, 5)\n","        ax.set_yticks([1, 2, 3, 4, 5])\n","        ax.set_yticklabels(['1', '2', '3', '4', '5'], size=10)\n","        ax.grid(True, linestyle='--', alpha=0.7, linewidth=1.2)\n","\n","        # ì œëª©\n","        plt.title('STAR + í˜‘ë™ì„± ìƒì„¸ í‰ê°€\\n(5ì  ë§Œì )',\n","                 size=16, weight='bold', pad=30)\n","\n","        # í•œê¸€ í°íŠ¸ ì„¤ì •\n","        plt.rcParams['font.family'] = 'DejaVu Sans'\n","        plt.rcParams['axes.unicode_minus'] = False\n","\n","        # ë²”ë¡€\n","        ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1), fontsize=11)\n","\n","        plt.tight_layout()\n","        plt.show()\n","\n","        print(\"\\nâœ… STAR ë ˆì´ë” ì°¨íŠ¸ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n","\n","    except Exception as e:\n","        print(f\"âŒ ë ˆì´ë” ì°¨íŠ¸ ìƒì„± ì‹¤íŒ¨: {str(e)}\")\n","        import traceback\n","        traceback.print_exc()\n","\n","    # 5. ìµœì¢… ì¢…í•© í”¼ë“œë°±\n","    print('\\n' + '='*80)\n","    print('[ìµœì¢… ì¢…í•© í”¼ë“œë°±]')\n","    print('='*80)\n","\n","    # ì „ì²´ ë©´ì ‘ ë‚´ìš© í…ìŠ¤íŠ¸í™”\n","    conversation_text = \"\\n\\n\".join([\n","        f\"ì§ˆë¬¸ {i+1}: {conv['ì§ˆë¬¸']}\\në‹µë³€ {i+1}: {conv['ë‹µë³€']}\"\n","        for i, conv in enumerate(state['conversation'])\n","    ])\n","\n","    # í‰ê°€ ê²°ê³¼ í…ìŠ¤íŠ¸í™”\n","    basic_summary = f\"ì§ˆë¬¸ ê´€ë ¨ì„±(ìƒ {relevance_counts['ìƒ']}, ì¤‘ {relevance_counts['ì¤‘']}, í•˜ {relevance_counts['í•˜']}), ë‹µë³€ êµ¬ì²´ì„±(ìƒ {specificity_counts['ìƒ']}, ì¤‘ {specificity_counts['ì¤‘']}, í•˜ {specificity_counts['í•˜']})\"\n","    star_summary = \"\\n\".join([\n","        f\"- {display_name}: {avg_scores[cat]}ì \"\n","        for cat, display_name in zip(categories, category_names)\n","    ])\n","\n","    # LLM ì¢…í•© í”¼ë“œë°±\n","    llm = ChatOpenAI(model_name='gpt-4.1-mini')\n","\n","    feedback_prompt = f'''\n","ì•„ë˜ ë©´ì ‘ ë‚´ìš©ê³¼ í‰ê°€ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§€ì›ìì—ê²Œ ìµœì¢… í”¼ë“œë°±ì„ ì‘ì„±í•´ì¤˜.\n","\n","=== ë©´ì ‘ ì§ˆë¬¸ ë° ë‹µë³€ ===\n","{conversation_text}\n","\n","=== ê¸°ë³¸ í‰ê°€ (ìƒ/ì¤‘/í•˜) ===\n","{basic_summary}\n","\n","=== STAR ìƒì„¸ í‰ê°€ (í‰ê· ) ===\n","{star_summary}\n","\n","ë‹¤ìŒ ë‚´ìš©ì„ í¬í•¨í•´ì„œ ì‘ì„±í•´ì¤˜:\n","\n","1. ê¸°ë³¸ í‰ê°€ ì¢…í•©\n","   - ì§ˆë¬¸ ê´€ë ¨ì„±ê³¼ ë‹µë³€ êµ¬ì²´ì„±ì— ëŒ€í•œ ì „ë°˜ì  í‰ê°€\n","   - ê°•ì ê³¼ ê°œì„ ì \n","\n","2. STAR ê° í•­ëª©ë³„ ë¶„ì„\n","   - S (ìƒí™©): ìƒí™© ì„¤ëª…ì˜ ê°•ì ê³¼ ê°œì„ ì \n","   - T (ì—­í• ): ì—­í• /ëª©í‘œ ì œì‹œì˜ ê°•ì ê³¼ ê°œì„ ì \n","   - A (í–‰ë™): í–‰ë™/ì˜ì‚¬ê²°ì •ì˜ ê°•ì ê³¼ ê°œì„ ì \n","   - R (ê²°ê³¼): ê²°ê³¼/ì„±ê³¼ ì œì‹œì˜ ê°•ì ê³¼ ê°œì„ ì \n","   - í˜‘ë™ì„±: íŒ€ì›Œí¬ ë° í˜‘ì—… ëŠ¥ë ¥ì˜ ê°•ì ê³¼ ê°œì„ ì \n","\n","3. ì „ì²´ ì´í‰\n","   - ì§€ì›ìì˜ í•µì‹¬ ê°•ì  (2-3ê°€ì§€)\n","   - ìš°ì„  ê°œì„ ì´ í•„ìš”í•œ ì˜ì—­ (2-3ê°€ì§€)\n","   - STAR ê¸°ë²• í™œìš© ê´€ì ì—ì„œì˜ ì¡°ì–¸\n","   - ë©´ì ‘ê´€ìœ¼ë¡œì„œì˜ ì¢…í•© ì˜ê²¬\n","   - ê²©ë ¤ì˜ í•œë§ˆë””\n","\n","ì „ë¬¸ì ì´ë©´ì„œë„ ë”°ëœ»í•œ í†¤ìœ¼ë¡œ ì‘ì„±í•˜ê³ ,\n","ì§€ì›ìê°€ ì‹¤ì œë¡œ í™œìš©í•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì ì¸ ì¡°ì–¸ì„ í¬í•¨í•´ì¤˜.\n","'''\n","\n","    feedback_messages = [\n","        SystemMessage(content=\"ë„ˆëŠ” ê²½ë ¥ 10ë…„ ì´ìƒì˜ STAR ë©´ì ‘ í”¼ë“œë°± ì „ë¬¸ê°€ì•¼.\"),\n","        HumanMessage(content=feedback_prompt)\n","    ]\n","\n","    feedback_response = llm.invoke(feedback_messages)\n","    final_report = feedback_response.content.strip()\n","\n","    print('\\n' + feedback_response.content.strip())\n","\n","    print('\\n' + '='*80)\n","    print('ì¸í„°ë·° í”¼ë“œë°± ë³´ê³ ì„œ ì™„ë£Œ')\n","    print('='*80 + '\\n')\n","\n","    #pdf ë‹¤ìš´ë¡œë“œ !pip reportlab ì„¤ì¹˜í•„ìš”\n","    pdfmetrics.registerFont(UnicodeCIDFont('HYSMyeongJo-Medium'))\n","    pdf_path = \"/content/interview_report.pdf\"\n","    doc = SimpleDocTemplate(pdf_path, pagesize=A4)\n","    styles = getSampleStyleSheet()\n","    styles = getSampleStyleSheet()\n","    styles[\"Normal\"].fontName = \"HYSMyeongJo-Medium\"\n","    styles[\"Title\"].fontName = \"HYSMyeongJo-Medium\"\n","    elements = []\n","    elements.append(Paragraph(\"AI ì¸í„°ë·° í‰ê°€ ë³´ê³ ì„œ\", styles[\"Title\"]))\n","    elements.append(Spacer(1, 20))\n","    elements.append(Paragraph(final_report.replace(\"\\n\", \"<br/>\"), styles[\"Normal\"]))\n","    elements.append(Spacer(1, 20))\n","    chart_path = \"/content/star_chart.png\"\n","    plt.savefig(chart_path)\n","    elements.append(Image(chart_path, width=400, height=350))\n","    doc.build(elements)\n","    plt.close()\n","    return {\n","        **state,\n","        \"final_report\": final_report,   # âœ… Gradioê°€ ì ‘ê·¼ ê°€ëŠ¥í•˜ë„ë¡ ì €ì¥\n","        \"pdf_path\" : pdf_path\n","    }\n","\n","\n","# 6) Agent --------------------\n","# ë¶„ê¸° íŒë‹¨ í•¨ìˆ˜\n","def route_next(state: InterviewState) -> Literal[\"generate\", \"summarize\"]:\n","    print(state['next_step'])\n","    return \"\" if state[\"next_step\"] == \"\" else \"end\"\n","\n","def check_satisfaction(state: InterviewState):\n","    return \"ì¬í‰ê°€ í•„ìš”\" if state[\"reflection_status\"] == \"ì¬í‰ê°€ í•„ìš”\" else \"ì •ìƒ\"\n","\n","# ê·¸ë˜í”„ ì •ì˜ ì‹œì‘\n","builder = StateGraph(InterviewState)\n","\n","# ë…¸ë“œ ì¶”ê°€\n","builder.add_node(\"evaluate\", evaluate_answer)\n","builder.add_node(\"reflect\", reflect_node)\n","builder.add_node(\"re_evaluate\", re_evaluate_answer)\n","builder.add_node(\"decide\", decide_next_step)\n","builder.add_node(\"generate\", generate_question)\n","builder.add_node(\"summarize\", summarize_interview)\n","\n","# ë…¸ë“œ ì—°ê²°\n","builder.add_conditional_edges(\"reflect\", check_satisfaction,\n","                              {\"ì •ìƒ\": \"decide\", \"ì¬í‰ê°€ í•„ìš”\": \"re_evaluate\"})\n","builder.add_conditional_edges(\"decide\", route_next,\n","                              {\"\": \"generate\", \"end\": \"summarize\"}\n","                              )\n","\n","builder.set_entry_point(\"evaluate\")\n","builder.add_edge(\"evaluate\", \"reflect\")\n","builder.add_edge(\"re_evaluate\", \"decide\")\n","builder.set_finish_point(\"generate\")\n","builder.set_finish_point(\"summarize\")\n","\n","# ì»´íŒŒì¼\n","graph = builder.compile()\n","#-------------------------------------------------------------------\n","\n","\n","########### ë‹¤ìŒ ì½”ë“œëŠ” ì œê³µë˜ëŠ” gradio ì½”ë“œ ì…ë‹ˆë‹¤.################\n","\n","import gradio as gr\n","import tempfile\n","\n","# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” í•¨ìˆ˜\n","def initialize_state():\n","    return {\n","        \"state\": None,\n","        \"interview_started\": False,\n","        \"interview_ended\": False,\n","        \"chat_history\": []\n","    }\n","\n","# íŒŒì¼ ì—…ë¡œë“œ í›„ ì¸í„°ë·° ì´ˆê¸°í™”\n","def upload_and_initialize(file_obj, session_state):\n","    if file_obj is None:\n","        return session_state, \"íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.\"\n","\n","    # GradioëŠ” file_obj.name ì´ íŒŒì¼ ê²½ë¡œì•¼\n","    file_path = file_obj.name\n","\n","    # ì¸í„°ë·° ì‚¬ì „ ì²˜ë¦¬\n","    state = preProcessing_Interview(file_path)\n","    session_state[\"state\"] = state\n","    session_state[\"interview_started\"] = True\n","\n","    # ì²« ì§ˆë¬¸ ì €ì¥\n","    first_question = state[\"current_question\"]\n","    session_state[\"chat_history\"].append([\"ğŸ¤– AI ë©´ì ‘ê´€\", first_question])\n","\n","    return session_state, session_state[\"chat_history\"]\n","\n","# ë‹µë³€ ì²˜ë¦¬ ë° ë‹¤ìŒ ì§ˆë¬¸ ìƒì„±\n","def chat_interview(user_input, session_state):\n","    if not session_state[\"interview_started\"]:\n","        return session_state, \"ë¨¼ì € ì´ë ¥ì„œë¥¼ ì—…ë¡œë“œí•˜ê³  ì¸í„°ë·°ë¥¼ ì‹œì‘í•˜ì„¸ìš”.\", gr.update(value=\"\"), None\n","\n","    # (1) ì‚¬ìš©ì ë‹µë³€ ì €ì¥\n","    session_state[\"chat_history\"].append([\"ğŸ™‹â€â™‚ï¸ ì§€ì›ì\", user_input])\n","    session_state[\"state\"] = update_current_answer(session_state[\"state\"], user_input)\n","\n","    # (2) Agent ì‹¤í–‰ (í‰ê°€ ë° ë‹¤ìŒ ì§ˆë¬¸ or ì¢…ë£Œ)\n","    session_state[\"state\"] = graph.invoke(session_state[\"state\"])\n","\n","    # (3) ì¢…ë£Œ ì—¬ë¶€ íŒë‹¨\n","    if session_state[\"state\"][\"next_step\"] == \"end\":\n","        session_state[\"interview_ended\"] = True\n","        final_summary = \"âœ… ì¸í„°ë·°ê°€ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\\n\\n\"\n","        final_report = session_state[\"state\"].get(\"final_report\", \"âš ï¸ ë³´ê³ ì„œ ìƒì„± ì˜¤ë¥˜\")\n","        pdf_path = session_state[\"state\"].get(\"pdf_path\", None)\n","        for i, turn in enumerate(session_state[\"state\"][\"conversation\"]):\n","            final_summary += f\"\\n**[ì§ˆë¬¸ {i+1}]** {turn['ì§ˆë¬¸']}\\n**[ë‹µë³€ {i+1}]** {turn['ë‹µë³€']}\\n\"\n","            if i < len(session_state[\"state\"][\"evaluation\"]):\n","                eval_result = session_state[\"state\"][\"evaluation\"][i]\n","                final_summary += f\"_í‰ê°€ - ì§ˆë¬¸ ê´€ë ¨ì„±: {eval_result['ì§ˆë¬¸ê³¼ì˜ ê´€ë ¨ì„±']}, ë‹µë³€ êµ¬ì²´ì„±: {eval_result['ë‹µë³€ì˜ êµ¬ì²´ì„±']}_\\n\"\n","        session_state[\"chat_history\"].append([\"ğŸ¤– AI ë©´ì ‘ê´€\", final_report])\n","        # ëŒ€í™” ëë‚˜ë©´ pdf ë‹¤ìš´ë²„íŠ¼ í™œì„±í™”\n","        return session_state, session_state[\"chat_history\"], gr.update(value=\"\"), gr.update(value=pdf_path, visible=True)\n","\n","    else:\n","        next_question = session_state[\"state\"][\"current_question\"]\n","        session_state[\"chat_history\"].append([\"ğŸ¤– AI ë©´ì ‘ê´€\", next_question])\n","        return session_state, session_state[\"chat_history\"], gr.update(value=\"\"), None\n","\n","# Gradio ì¸í„°í˜ì´ìŠ¤ êµ¬ì„±\n","with gr.Blocks() as demo:\n","    session_state = gr.State(initialize_state())\n","\n","    gr.Markdown(\"# ğŸ¤– AI ë©´ì ‘ê´€ \\nì´ë ¥ì„œë¥¼ ì—…ë¡œë“œí•˜ê³  ì¸í„°ë·°ë¥¼ ì‹œì‘í•˜ì„¸ìš”!\")\n","\n","    with gr.Row():\n","        file_input = gr.File(label=\"ì´ë ¥ì„œ ì—…ë¡œë“œ (PDF ë˜ëŠ” DOCX)\")\n","        upload_btn = gr.Button(\"ì¸í„°ë·° ì‹œì‘\")\n","\n","    chatbot = gr.Chatbot()\n","    user_input = gr.Textbox(show_label=False, placeholder=\"ë‹µë³€ì„ ì…ë ¥í•˜ê³  Enterë¥¼ ëˆ„ë¥´ì„¸ìš”.\")\n","    #pdf ë‹¤ìš´ ë²„íŠ¼\n","    download_btn = gr.File(label=\"ğŸ“„ ì¸í„°ë·° ê²°ê³¼ ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ\", visible=False)\n","\n","    #pdf\n","    upload_btn.click(upload_and_initialize, inputs=[file_input, session_state], outputs=[session_state, chatbot])\n","    user_input.submit(chat_interview, inputs=[user_input, session_state], outputs=[session_state, chatbot,user_input, download_btn])\n","    user_input.submit(lambda: \"\", None, user_input)\n","\n","# ì‹¤í–‰\n","demo.launch(share=True)"],"metadata":{"id":"Uy7qNKtWkNYp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **3. ì‹¤í–‰**"],"metadata":{"id":"vVw8pSQRyy73"}},{"cell_type":"code","source":["!python app.py"],"metadata":{"id":"jAPn8nhOkCJO"},"execution_count":null,"outputs":[]}]}